{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pos_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "def unsqueeze_at_end(tensor: Tensor, ndim_out: int) -> Tensor:\n",
    "    ndim_in = tensor.ndim\n",
    "    assert ndim_out >= ndim_in\n",
    "    extra_dims_shape = (1,) * (ndim_out - ndim_in)\n",
    "    return tensor.reshape(*tensor.shape, *extra_dims_shape)\n",
    "\n",
    "a = torch.arange(5)\n",
    "unsqueeze_at_end(a, 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [-8.],\n",
       "         [-1.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [-0.],\n",
       "         [-6.],\n",
       "         [ 2.]],\n",
       "\n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [-7.],\n",
       "         [-5.],\n",
       "         [ 3.]],\n",
       "\n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 2.],\n",
       "         [-1.],\n",
       "         [-6.]],\n",
       "\n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 5.],\n",
       "         [ 1.]],\n",
       "\n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [-2.],\n",
       "         [-4.],\n",
       "         [-4.]],\n",
       "\n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 6.],\n",
       "         [-1.],\n",
       "         [-3.]],\n",
       "\n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 7.],\n",
       "         [ 5.],\n",
       "         [-8.]],\n",
       "\n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [-7.],\n",
       "         [ 2.],\n",
       "         [ 1.]],\n",
       "\n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [-6.],\n",
       "         [12.],\n",
       "         [-2.]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch, pos = 10, 3\n",
    "pos_act = 6\n",
    "d_model = 1\n",
    "\n",
    "batch_idx = torch.arange(batch * pos).reshape(batch, pos)\n",
    "# pos_idx = torch.zeros(batch, pos).long()\n",
    "pos_idx = torch.randint(0, pos, (batch, pos))\n",
    "\n",
    "activations = 5 * torch.randn(batch, pos_act, d_model)\n",
    "new_activactions = torch.zeros(batch * pos, pos_act, d_model)\n",
    "\n",
    "pos_map = torch.arange(pos)\n",
    "# pos_map = torch.stack([pos_map, pos_map + pos], dim=1)\n",
    "\n",
    "new_pos_idx = pos_map[pos_idx]\n",
    "act_pos_idx = pos_map.repeat(batch, 1)\n",
    "\n",
    "activations[unsqueeze_at_end(torch.arange(batch), act_pos_idx.ndim), act_pos_idx] =  new_activactions[unsqueeze_at_end(batch_idx, new_pos_idx.ndim), new_pos_idx]\n",
    "np.round(activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 7]\n",
      "[2, 4, 7]\n",
      "[1, 5, 7]\n",
      "[1, 6, 7]\n",
      "[1, 4, 8]\n",
      "[1, 4, 9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Example\n",
    "x = [[1, 2], [4, 5, 6], [7, 8, 9]]\n",
    "for tup in yield_default_and_one_off_variations(*x):\n",
    "    print(tup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
